{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f85cf25b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "# load yolov3 model and perform object detection\n",
    "# we will use a pre-trained model to perform object detection on an unseen photograph\n",
    "from numpy import expand_dims\n",
    "from keras.models import load_model\n",
    "# from keras.preprocessing.image import img_to_array\n",
    "from keras_preprocessing.image import load_img\n",
    "\n",
    "# from Yolo_v3 import model\n",
    "\n",
    "# load yolov3 model\n",
    "model = load_model('model.h5')\n",
    "\n",
    "# define the expected input shape for the model\n",
    "input_w, input_h = 416, 416"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "349d3f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load yolov3 model and perform object detection\n",
    "\n",
    "import numpy as np\n",
    "from numpy import expand_dims\n",
    "from keras.models import load_model\n",
    "from keras_preprocessing.image import load_img\n",
    "from keras_preprocessing.image import img_to_array\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "class BoundBox:\n",
    "\tdef __init__(self, xmin, ymin, xmax, ymax, objness = None, classes = None):\n",
    "\t\tself.xmin = xmin\n",
    "\t\tself.ymin = ymin\n",
    "\t\tself.xmax = xmax\n",
    "\t\tself.ymax = ymax\n",
    "\t\tself.objness = objness\n",
    "\t\tself.classes = classes\n",
    "\t\tself.label = -1\n",
    "\t\tself.score = -1\n",
    "\n",
    "\tdef get_label(self):\n",
    "\t\tif self.label == -1:\n",
    "\t\t\tself.label = np.argmax(self.classes)\n",
    "\n",
    "\t\treturn self.label\n",
    "\n",
    "\tdef get_score(self):\n",
    "\t\tif self.score == -1:\n",
    "\t\t\tself.score = self.classes[self.get_label()]\n",
    "\n",
    "\t\treturn self.score\n",
    "\n",
    "\n",
    "def _sigmoid(x):\n",
    "\treturn 1. / (1. + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9d9ee5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_netout(netout, anchors, obj_thresh, net_h, net_w):\n",
    "\tgrid_h, grid_w = netout.shape[:2] # 0 and 1 is row and column 13*13\n",
    "\tnb_box = 3 # 3 anchor boxes\n",
    "\tnetout = netout.reshape((grid_h, grid_w, nb_box, -1)) #13*13*3 ,-1\n",
    "\tnb_class = netout.shape[-1] - 5\n",
    "\tboxes = []\n",
    "\tnetout[..., :2]  = _sigmoid(netout[..., :2])\n",
    "\tnetout[..., 4:]  = _sigmoid(netout[..., 4:])\n",
    "\tnetout[..., 5:]  = netout[..., 4][..., np.newaxis] * netout[..., 5:]\n",
    "\tnetout[..., 5:] *= netout[..., 5:] > obj_thresh\n",
    "\n",
    "\tfor i in range(grid_h*grid_w):\n",
    "\t\trow = i / grid_w\n",
    "\t\tcol = i % grid_w\n",
    "\t\tfor b in range(nb_box):\n",
    "\t\t\t# 4th element is objectness score\n",
    "\t\t\tobjectness = netout[int(row)][int(col)][b][4]\n",
    "\t\t\tif(objectness.all() <= obj_thresh): continue\n",
    "\t\t\t# first 4 elements are x, y, w, and h\n",
    "\t\t\tx, y, w, h = netout[int(row)][int(col)][b][:4]\n",
    "\t\t\tx = (col + x) / grid_w # center position, unit: image width\n",
    "\t\t\ty = (row + y) / grid_h # center position, unit: image height\n",
    "\t\t\tw = anchors[2 * b + 0] * np.exp(w) / net_w # unit: image width\n",
    "\t\t\th = anchors[2 * b + 1] * np.exp(h) / net_h # unit: image height\n",
    "\t\t\t# last elements are class probabilities\n",
    "\t\t\tclasses = netout[int(row)][col][b][5:]\n",
    "\t\t\tbox = BoundBox(x-w/2, y-h/2, x+w/2, y+h/2, objectness, classes)\n",
    "\t\t\tboxes.append(box)\n",
    "\treturn boxes\n",
    "\n",
    "\n",
    "def correct_yolo_boxes(boxes, image_h, image_w, net_h, net_w):\n",
    "\tnew_w, new_h = net_w, net_h\n",
    "\tfor i in range(len(boxes)):\n",
    "\t\tx_offset, x_scale = (net_w - new_w)/2./net_w, float(new_w)/net_w\n",
    "\t\ty_offset, y_scale = (net_h - new_h)/2./net_h, float(new_h)/net_h\n",
    "\t\tboxes[i].xmin = int((boxes[i].xmin - x_offset) / x_scale * image_w)\n",
    "\t\tboxes[i].xmax = int((boxes[i].xmax - x_offset) / x_scale * image_w)\n",
    "\t\tboxes[i].ymin = int((boxes[i].ymin - y_offset) / y_scale * image_h)\n",
    "\t\tboxes[i].ymax = int((boxes[i].ymax - y_offset) / y_scale * image_h)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95962494",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _interval_overlap(interval_a, interval_b):\n",
    "\tx1, x2 = interval_a\n",
    "\tx3, x4 = interval_b\n",
    "\tif x3 < x1:\n",
    "\t\tif x4 < x1:\n",
    "\t\t\treturn 0\n",
    "\t\telse:\n",
    "\t\t\treturn min(x2,x4) - x1\n",
    "\telse:\n",
    "\t\tif x2 < x3:\n",
    "\t\t\t return 0\n",
    "\t\telse:\n",
    "\t\t\treturn min(x2,x4) - x3\n",
    "\n",
    "#intersection over union        \n",
    "def bbox_iou(box1, box2):\n",
    "\tintersect_w = _interval_overlap([box1.xmin, box1.xmax], [box2.xmin, box2.xmax])\n",
    "\tintersect_h = _interval_overlap([box1.ymin, box1.ymax], [box2.ymin, box2.ymax])\n",
    "\tintersect = intersect_w * intersect_h\n",
    "    \n",
    "    \n",
    "\tw1, h1 = box1.xmax-box1.xmin, box1.ymax-box1.ymin  \n",
    "\tw2, h2 = box2.xmax-box2.xmin, box2.ymax-box2.ymin\n",
    "    \n",
    "    #Union(A,B) = A + B - Inter(A,B)\n",
    "\tunion = w1*h1 + w2*h2 - intersect\n",
    "\treturn float(intersect) / union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "551527b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_nms(boxes, nms_thresh):    #boxes from correct_yolo_boxes and  decode_netout\n",
    "\tif len(boxes) > 0:\n",
    "\t\tnb_class = len(boxes[0].classes)\n",
    "\telse:\n",
    "\t\treturn\n",
    "\tfor c in range(nb_class):\n",
    "\t\tsorted_indices = np.argsort([-box.classes[c] for box in boxes])\n",
    "\t\tfor i in range(len(sorted_indices)):\n",
    "\t\t\tindex_i = sorted_indices[i]\n",
    "\t\t\tif boxes[index_i].classes[c] == 0: continue\n",
    "\t\t\tfor j in range(i+1, len(sorted_indices)):\n",
    "\t\t\t\tindex_j = sorted_indices[j]\n",
    "\t\t\t\tif bbox_iou(boxes[index_i], boxes[index_j]) >= nms_thresh:\n",
    "\t\t\t\t\tboxes[index_j].classes[c] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1525ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and prepare an image\n",
    "def load_image_pixels(filename, shape):\n",
    "\t# load the image to get its shape\n",
    "\timage = load_img(filename) #load_img() Keras function to load the image .\n",
    "\twidth, height = image.size\n",
    "\t# load the image with the required size\n",
    "\timage = load_img(filename, target_size=shape) # target_size argument to resize the image after loading\n",
    "\t# convert to numpy array\n",
    "\timage = img_to_array(image)\n",
    "\t# scale pixel values to [0, 1]\n",
    "\timage = image.astype('float32')\n",
    "\timage /= 255.0  #rescale the pixel values from 0-255 to 0-1 32-bit floating point values.\n",
    "\t# add a dimension so that we have one sample\n",
    "\timage = expand_dims(image, 0)\n",
    "\treturn image, width, height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7346490",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import expand_dims\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "\n",
    "photo_filename = 'zebra.jpg'\n",
    "input_w, input_h = 416, 416\n",
    "# load and prepare image\n",
    "image, image_w, image_h = load_image_pixels(photo_filename, (input_w, input_h))\n",
    "#print(image, image_w, image_h )\n",
    "print(image.shape)\n",
    "# make prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
